{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6558233",
   "metadata": {},
   "source": [
    "# cross_validate\n",
    "\n",
    "from scikit-learn tutorial, https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60768f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af1fc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b24c663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The simplest way to use cross-validation is to call the\n",
    "# cross_val_score helper function on the estimator and the dataset.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8e5ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When the cv argument is an integer, cross_val_score uses\n",
    "# the KFold or StratifiedKFold strategies by default,\n",
    "# the latter being used if the estimator derives from ClassifierMixin.\n",
    "\n",
    "# It is also possible to use other cross validation strategies \n",
    "# by passing a cross validation iterator instead, for instance:\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a16b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another option is to use an iterable yielding \n",
    "# (train, test) splits as arrays of indices, for example:\n",
    "def custom_cv_2folds(X):\n",
    "     n = X.shape[0]\n",
    "     i = 1\n",
    "     while i <= 2:\n",
    "         idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "         yield idx, idx\n",
    "         i += 1\n",
    "\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c8d52b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as it is important to test a predictor on data held-out from \n",
    "# training, preprocessing (such as standardization, feature selection, etc.) \n",
    "# and similar data transformations similarly should be learnt from a \n",
    "# training set and applied to held-out data for prediction:\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f1291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Pipeline makes it easier to compose estimators, providing this behavior \n",
    "# under cross-validation:\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b6b8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cross_validate function differs from cross_val_score in two ways:\n",
    "\n",
    "# It allows specifying multiple metrics for evaluation.\n",
    "\n",
    "# It returns a dict containing fit-times, score-times (and optionally \n",
    "# training scores, fitted estimators, train-test split indices) in addition \n",
    "# to the test score.\n",
    "\n",
    "# For single metric evaluation, where the scoring parameter is a string, \n",
    "# callable or None, the keys will be - ['test_score', 'fit_time', \n",
    "# 'score_time']\n",
    "\n",
    "# And for multiple metric evaluation, the return value is a dict with the \n",
    "# following keys - ['test_<scorer1_name>', 'test_<scorer2_name>', \n",
    "# 'test_<scorer...>', 'fit_time', 'score_time']\n",
    "\n",
    "# return_train_score is set to False by default to save computation time. To \n",
    "# evaluate the scores on the training set as well you need to set it to \n",
    "# True. You may also retain the estimator fitted on each training set by \n",
    "# setting return_estimator=True. Similarly, you may set return_indices=True \n",
    "# to retain the training and testing indices used to split the dataset into \n",
    "# train and test sets for each cv split.\n",
    "\n",
    "# The multiple metrics can be specified either as a list, tuple or set of \n",
    "# predefined scorer names:\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys()) # ['fit_time', 'score_time', \n",
    "# 'test_precision_macro', 'test_recall_macro']\n",
    "scores['test_recall_macro']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307cb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
